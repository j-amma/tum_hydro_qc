{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55d50933",
   "metadata": {},
   "source": [
    "# Normalize Raw Levelogger and Barologger Data\n",
    "\n",
    "This notebook ingests raw levelogger and barologger data from each year, outputing new level/baro files with consistent naming conventions, headers, and units. Additionally, if the input data is from a levelogger, a log file will be created and populated with the metadata extracted from the raw input file. **This should be run once at the beginning of the project**\n",
    "\n",
    "Essentially, this notebook adjusts the raw data to conform to conventions specified in config.py. \n",
    "\n",
    "**Note:**\n",
    "* All processing templates expect data to be formatted according to the conventions implemented by this notebook\n",
    "* This notebook assumes each year of raw data has its own directory\n",
    "\n",
    "\n",
    "Author of Template and Underlying Code: Joe Ammatelli | (jamma@uw.edu) | July 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c6c815",
   "metadata": {},
   "source": [
    "## Import Relevant Libraries\n",
    "**Analyst TODO**: Nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2e34a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join('..', 'src')))\n",
    "\n",
    "import config\n",
    "import level_baro_utils\n",
    "import log_utils\n",
    "\n",
    "sys.path.remove(os.path.abspath(os.path.join('..', 'src')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc5ffa1",
   "metadata": {},
   "source": [
    "## Specify path to each year of data\n",
    "**Analyst TODO**: Create a string mapping between each year ('YYYY') and the corresponding path to its raw data ('path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e442f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: populate dictionary with mappings between year of data and path to raw data\n",
    "# Example\n",
    "# raw_data_dir_by_year = {'2019':'~/tum_raw/raw_19',\n",
    "#                         '2020':'~/tum_raw/raw_20',\n",
    "#                         '2021':'~/tum_raw/raw_21'}\n",
    "\n",
    "raw_data_dir_by_year = {'year' : 'path'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72240e3",
   "metadata": {},
   "source": [
    "## Normalize Each Year of Data\n",
    "\n",
    "**Analyst TODO**: Nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec92b497",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************\n",
      "Normalizing Data for Year: 2019\n",
      "*******************************\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../unvented_2019/data/raw'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3dd820f51344>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mraw_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc_year_dir_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'raw'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# create dir to store normalized data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../unvented_2019/data/raw'"
     ]
    }
   ],
   "source": [
    "for year in raw_data_dir_by_year:\n",
    "    print('*******************************')\n",
    "    print(f'Normalizing Data for Year: {year}')\n",
    "    print('*******************************\\n')\n",
    "    \n",
    "    # read data from correct year\n",
    "    data_dir = raw_data_dir_by_year[year]\n",
    "    \n",
    "    # write output to correct place\n",
    "    loc_year_dir_path = os.path.join('..', f'unvented_{year}')\n",
    "    \n",
    "    # create directory to store raw data\n",
    "    raw_dir = os.path.join(loc_year_dir_path, 'data', 'raw')\n",
    "    if not os.path.exists(raw_dir):\n",
    "        os.mkdir(raw_dir)\n",
    "    \n",
    "    # create dir to store normalized data\n",
    "    norm_dir = os.path.join(loc_year_dir_path, 'data', 'normalized_raw')\n",
    "    if not os.path.exists(norm_dir):\n",
    "        os.mkdir(norm_dir)\n",
    "    \n",
    "    # normalize each file in directory\n",
    "    for fn in os.listdir(data_dir):\n",
    "        if fn[0] == '.':\n",
    "            continue\n",
    "            \n",
    "        print(f'Normalizing {fn}')\n",
    "        \n",
    "        f_path = os.path.join(data_dir, fn)\n",
    "        \n",
    "        # infer site\n",
    "        sitekey = level_baro_utils.infer_site_from_name(fn)\n",
    "        sitename = None\n",
    "        if sitekey is None:\n",
    "            sitename = fn.split('_')[0]\n",
    "        else:\n",
    "            sitename = config.SITE_SHORTNAME[sitekey]\n",
    "        \n",
    "        # infer sensor type\n",
    "        sensor_type = level_baro_utils.infer_sensor_type_from_name(fn)\n",
    "        \n",
    "        # find header start and read file metadata\n",
    "        meta, header_num = level_baro_utils.read_meta(f_path)\n",
    "        \n",
    "        # read data, convert to desired units, normalize header name\n",
    "        df = level_baro_utils.read_normalize_solinst_data(f_path, header_num, sensor_type)\n",
    "    \n",
    "        # save raw data to\n",
    "        raw_path = os.path.join(raw_dir, fn)\n",
    "        shutil.copyfile(f_path, raw_path)\n",
    "        \n",
    "        # save normalized file according to naming_convention\n",
    "        data_name = config.NORMALIZED_FN.format(sensor_type=sensor_type, \n",
    "                                                sitename=sitename, \n",
    "                                                year=year)\n",
    "        data_path = os.path.join(norm_dir, data_name)\n",
    "        df.to_csv(data_path)\n",
    "        \n",
    "        # create log file for site and append meta data\n",
    "        if sensor_type == 'lvl':\n",
    "            log_dir = os.path.join(loc_year_dir_path, 'logs')\n",
    "            log_name = f'{sitename}_{year}_log.txt'\n",
    "            log_path = os.path.join(log_dir, log_name)\n",
    "            log_utils.create_site_log(log_path, sitename, year)\n",
    "            log_utils.append_to_log(log_path, 'RAW SOLINST META DATA\\n', ''.join(meta))\n",
    "        \n",
    "        print(f'Finished Normalizing {fn}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb41a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
